{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:01<00:00, 6.24MB/s]\n",
      "Ultralytics YOLOv8.0.150  Python-3.11.4 torch-2.0.1 CPU (Intel Core(TM) i9-10980XE 3.00GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.8s, saved as 'yolov8n.torchscript' (12.5 MB)\n",
      "\n",
      "Export complete (11.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\kawaw\\Catching\\Catching2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640 \n",
      "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n.torchscript'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load an official model\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"torchscript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from torchvision.models import yolov7\n",
    "from models.yolo import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawaw\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "WEIGHT = r\"C:\\Users\\kawaw\\yolo_train\\yolov7\\runs\\train\\color202308225\\weights\\best.pt\"#\"C:\\Users\\kawaw\\yolo_train\\yolov7\\runs\\train\\20230718\\weights\\best.pt\"#\"C:\\Users\\kawaw\\yolo_train\\yolov7\\runs\\train\\gray_20230718\\weights\\best.pt\"#r\"C:\\Users\\kawaw\\Catching\\imgs\\data_RSJ\\yolov7.pt\"#\"C:\\Users\\kawaw\\Catching\\Catching2\\yolov7\\weights\\gray_202302\\weights\\best.pt\"\n",
    "results_yolo1 = []\n",
    "results_yolo2 = []\n",
    "\n",
    "def load_yolo(device=DEVICE, path_or_model=WEIGHT, autoshape=True):\n",
    "    \"\"\"custom mode\n",
    "\n",
    "    Arguments (3 options):\n",
    "        device : CPU or GPU\n",
    "        path_or_model : Model Weight path\n",
    "        autoshape : convert img size to fit the model input\n",
    "\n",
    "    Returns:\n",
    "        pytorch model\n",
    "    \"\"\"\n",
    "    #model = torch.load(path_or_model, map_location=device) if isinstance(path_or_model, str) else path_or_model\n",
    "    model = torch.load(path_or_model, map_location=device) if isinstance(path_or_model, str) else path_or_model\n",
    "    # load checkpoint\n",
    "    if isinstance(model, dict):\n",
    "        model = model[\"ema\" if model.get(\"ema\") else \"model\"]  # load model\n",
    "    hub_model = Model(model.yaml).to(next(model.parameters()))#.device)  # create\n",
    "    hub_model.load_state_dict(model.float().state_dict())  # load state_dict\n",
    "    r\"\"\"\n",
    "    hub_model.names = model.names  # class names\n",
    "    if autoshape:\n",
    "        hub_model = hub_model.autoshape()  # for file\\URI\\PIL\\cv2\\np inputs and NMS\n",
    "    \"\"\"\n",
    "    return hub_model#.to(device)\n",
    "\n",
    "model = load_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (4): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (6): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (8): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (9): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (10): Concat()\n",
       "    (11): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (12): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (13): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (15): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (16): Concat()\n",
       "    (17): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (19): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (20): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (21): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (22): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (23): Concat()\n",
       "    (24): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (25): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (26): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (27): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (28): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (29): Concat()\n",
       "    (30): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (31): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (32): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (33): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (34): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (35): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (36): Concat()\n",
       "    (37): Conv(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (38): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (39): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (40): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (41): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (42): Concat()\n",
       "    (43): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (44): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (45): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (46): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (47): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (48): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (49): Concat()\n",
       "    (50): Conv(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (51): SPPCSPC(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv4): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (cv5): Conv(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv6): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv7): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (52): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (53): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (54): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (55): Concat()\n",
       "    (56): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (57): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (58): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (59): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (60): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (61): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (62): Concat()\n",
       "    (63): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (64): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (65): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (66): Conv(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (67): Concat()\n",
       "    (68): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (69): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (70): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (71): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (72): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (73): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (74): Concat()\n",
       "    (75): Conv(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (76): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (77): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (78): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (79): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (80): Concat()\n",
       "    (81): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (82): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (83): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (84): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (85): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (86): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (87): Concat()\n",
       "    (88): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (89): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (90): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (91): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (92): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (93): Concat()\n",
       "    (94): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (95): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (96): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (97): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (98): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (99): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (100): Concat()\n",
       "    (101): Conv(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (102): RepConv(\n",
       "      (act): SiLU()\n",
       "      (rbr_dense): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (rbr_1x1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (103): RepConv(\n",
       "      (act): SiLU()\n",
       "      (rbr_dense): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (rbr_1x1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (104): RepConv(\n",
       "      (act): SiLU()\n",
       "      (rbr_dense): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (rbr_1x1): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (105): IDetect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (ia): ModuleList(\n",
       "        (0-2): 3 x ImplicitA()\n",
       "      )\n",
       "      (im): ModuleList(\n",
       "        (0-2): 3 x ImplicitM()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose.pt to 'yolov8x-pose.pt'...\n",
      "100%|██████████| 133M/133M [00:27<00:00, 5.07MB/s] \n",
      "Ultralytics YOLOv8.0.150  Python-3.11.4 torch-2.0.1 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLOv8x-pose summary (fused): 287 layers, 69462204 parameters, 0 gradients, 263.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8x-pose.pt' with input shape (1, 3, 320, 640) BCHW and output shape(s) (1, 56, 4200) (133.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  3.5s, saved as 'yolov8x-pose.torchscript' (265.6 MB)\n",
      "\n",
      "Export complete (11.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\kawaw\\Catching\\Catching2\u001b[0m\n",
      "Predict:         yolo predict task=pose model=yolov8x-pose.torchscript imgsz=320,640 \n",
      "Validate:        yolo val task=pose model=yolov8x-pose.torchscript imgsz=320,640 data=/usr/src/app/ultralytics/datasets/coco-pose.yaml WARNING  non-PyTorch val requires square images, 'imgsz=[320, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO(r'C:\\Users\\kawaw\\yolo_train\\yolov5\\yolov5\\runs\\train\\exp2\\weights\\best.pt')\n",
    "#yolov8\n",
    "torch.cuda.set_device(0)\n",
    "with torch.no_grad():\n",
    "    model = YOLO(\"yolov8x-pose.pt\")#C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train26\\weights\\last.pt\")#\"yolov8s-pose.pt\")#r\"C:\\Users\\kawaw\\Catching\\yolov8\\runs\\detect\\train7\\weights\\last.pt\")  # load an official model\n",
    "    model.to(DEVICE)\n",
    "    # Export the model\n",
    "    model.export(format=\"torchscript\",imgsz=(320,640),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),opset=12)#,nms=True)#,imgsz=320)#,opset=12)#,dynamic=True)\n",
    "    #model.export(format=\"torchscript\",imgsz=(320,320),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))#,opset=12)#,imgsz=320)#,opset=12)#,dynamic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.150  Python-3.11.4 torch-2.0.1 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "Model summary (fused): 218 layers, 25840918 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\\best.pt' with input shape (1, 3, 320, 640) BCHW and output shape(s) (1, 6, 4200) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.4s, saved as 'C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\\best.torchscript' (99.1 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\\best.torchscript imgsz=320,640 \n",
      "Validate:        yolo val task=detect model=C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\\best.torchscript imgsz=320,640 data=C:\\Users\\kawaw\\dataset_yolo\\1026\\1026.yaml WARNING  non-PyTorch val requires square images, 'imgsz=[320, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO(r'C:\\Users\\kawaw\\yolo_train\\yolov5\\yolov5\\runs\\train\\exp2\\weights\\best.pt')\n",
    "#yolov8\n",
    "torch.cuda.set_device(0)\n",
    "with torch.no_grad():\n",
    "    model = YOLO(r'C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train7\\weights\\best.pt') #C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train26\\weights\\last.pt\")#\"yolov8s-pose.pt\")#r\"C:\\Users\\kawaw\\Catching\\yolov8\\runs\\detect\\train7\\weights\\last.pt\")  # load an official model\n",
    "    model.to(DEVICE)\n",
    "    # Export the model\n",
    "    model.export(format=\"torchscript\",imgsz=(320,640),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))#,nms=True)#,imgsz=320)#,opset=12)#,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 3)\n",
      "img device :  cuda:0\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = torch.jit.load(r\"C:\\Users\\kawaw\\Catching\\yolov8\\ultralytics\\runs\\detect\\train3\\weights\\best.torchscript\")\n",
    "model.to(DEVICE)\n",
    "img = cv2.imread(r\"C:\\Users\\kawaw\\Catching\\Catching2\\900.jpg\")\n",
    "img = np.resize(img,(320,320,3))\n",
    "print(img.shape)\n",
    "img = np.transpose(img, (2,0,1))\n",
    "img = img/255\n",
    "#print(img)\n",
    "img = np.expand_dims(img,0)\n",
    "#print(img.shape)\n",
    "img = torch.tensor(img)\n",
    "#print(type(img))\n",
    "img = img.to(DEVICE)\n",
    "img = img.float()\n",
    "print(\"img device : \",img.device)\n",
    "#print(\"model device : \",model(img))\n",
    "results = model(img)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7638, 0.1220, 0.1807, 0.5058, 0.9446, 0.8489],\n",
      "        [0.7017, 0.8262, 0.2976, 0.4297, 0.1198, 0.5404],\n",
      "        [0.3391, 0.0707, 0.9644, 0.0716, 0.0301, 0.9550],\n",
      "        ...,\n",
      "        [0.1397, 0.2478, 0.6676, 0.1564, 0.1549, 0.5620],\n",
      "        [0.1454, 0.3586, 0.1763, 0.6033, 0.8533, 0.2456],\n",
      "        [0.2667, 0.5399, 0.9536, 0.7667, 0.7580, 0.5587]])\n",
      "tensor([0.7017, 0.8262, 0.2976, 0.4297, 0.1198, 0.5404])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand((2100,6))\n",
    "print(t)\n",
    "x = t.select(0,1)\n",
    "print(x)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not get name of python class object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mkawaw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCatching\u001b[39m\u001b[39m\\\u001b[39m\u001b[39myolov8\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdetect\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtrain3\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbest.pt\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# load an official model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m6400\u001b[39m, \u001b[39m640\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m traced_from_pytorch_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, img)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinish tracing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# TraceしたものをTorchScript ModelとしてSave\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\torch\\jit\\_trace.py:846\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m    841\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n\u001b[1;32m--> 846\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m    847\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(example_kwarg_inputs, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    848\u001b[0m     example_inputs \u001b[39m=\u001b[39m example_kwarg_inputs\n",
      "File \u001b[1;32mc:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\torch\\_jit_internal.py:1145\u001b[0m, in \u001b[0;36m_qualified_name\u001b[1;34m(obj, mangle_name)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mname\n\u001b[0;32m   1144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not get name of python class object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<lambda>\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1148\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_lambda\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# make name a valid identifier\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not get name of python class object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(model=r\"C:\\Users\\kawaw\\Catching\\yolov8\\runs\\detect\\train3\\weights\\best.pt\")  # load an official model\n",
    "\n",
    "\n",
    "img = torch.rand(1, 3, 320,320)\n",
    "traced_from_pytorch_model = torch.jit.trace(model, img)\n",
    "print(\"finish tracing\")\n",
    "\n",
    "# TraceしたものをTorchScript ModelとしてSave\n",
    "traced_from_pytorch_model.save(\"20230823.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 3)\n",
      "(1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not get name of python class object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     11\u001b[0m traced_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mkawaw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39myolo_train\u001b[39m\u001b[39m\\\u001b[39m\u001b[39myolov7\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m20230718\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbest.torchscript\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m traced_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model,img)\n",
      "File \u001b[1;32mc:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\torch\\jit\\_trace.py:846\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m    841\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n\u001b[1;32m--> 846\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m    847\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(example_kwarg_inputs, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    848\u001b[0m     example_inputs \u001b[39m=\u001b[39m example_kwarg_inputs\n",
      "File \u001b[1;32mc:\\Users\\kawaw\\anaconda3\\envs\\kawawaki\\Lib\\site-packages\\torch\\_jit_internal.py:1145\u001b[0m, in \u001b[0;36m_qualified_name\u001b[1;34m(obj, mangle_name)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mname\n\u001b[0;32m   1144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not get name of python class object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<lambda>\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1148\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_lambda\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# make name a valid identifier\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not get name of python class object"
     ]
    }
   ],
   "source": [
    "#img = cv2.imread(r\"C:\\Users\\kawaw\\Catching\\Catching2\\900.jpg\")\n",
    "img = torch.rand(1, 3, 320, 320)\n",
    "print(img.shape)\n",
    "#img = np.resize(img,(640,640,3))\n",
    "#img = np.transpose(img, (2,0,1))\n",
    "#img = img/255 #normalization\n",
    "#img = np.expand_dims(img,0)\n",
    "print(img.shape)\n",
    "#img = torch.tensor(img)\n",
    "#img = img.double()\n",
    "#img = img.to(DEVICE)\n",
    "traced_model = torch.jit.load(r\"C:\\Users\\kawaw\\yolo_train\\yolov7\\runs\\train\\20230718\\weights\\best.torchscript\")\n",
    "traced_model = torch.jit.trace(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 640, 640)\n",
      "torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawaw\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_trace.py:1056: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Define a dummy input tensor with the appropriate shape (batch_size, channels, height, width)\n",
    "img = torch.rand(320,320,3)\n",
    "img = np.resize(img,(640,640,3))\n",
    "img = np.transpose(img, (2,0,1))\n",
    "#img = img/255 #normalization\n",
    "img = np.expand_dims(img,0)\n",
    "print(img.shape)\n",
    "img = torch.tensor(img)\n",
    "img = img.half()\n",
    "print(img.dtype)\n",
    "img = img.to(DEVICE)\n",
    "\n",
    "#img = img.to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# Trace the model to obtain the TorchScript representation\n",
    "traced_script_module = torch.jit.trace(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(r\"C:\\Users\\kawaw\\cpp\\torchScript\\20230809.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#load torch script model and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 3)\n",
      "torch.float16\n",
      "torch.Size([1, 3, 80, 80, 7])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "img = cv2.imread(r\"C:\\Users\\kawaw\\Catching\\Catching2\\900.jpg\")\n",
    "img = np.resize(img,(640,640,3))\n",
    "print(img.shape)\n",
    "img = np.transpose(img, (2,0,1))\n",
    "img = img/255\n",
    "img = np.expand_dims(img,0)\n",
    "#print(img.shape)\n",
    "img = torch.tensor(img)\n",
    "#print(type(img))\n",
    "img = img.half()\n",
    "img = img.to(DEVICE)\n",
    "print(img.dtype)\n",
    "model = torch.jit.load(r\"C:\\Users\\kawaw\\cpp\\torchScript\\20230809.pt\")#r\"C:\\Users\\kawaw\\Catching\\yolov8\\runs\\detect\\train3\\weights\\best.torchscript\")\n",
    "with torch.no_grad():\n",
    "    results = model.forward(img)\n",
    "\n",
    "print(results[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kawawaki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
